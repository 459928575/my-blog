## 什么是Baseline Model？记和硅谷大佬的一次吃饭

在大概两周前，硅谷的一家普通中国餐厅。

我正在和一位大公司的硅谷精英吃饭（A开头的公司，但不是Amazon，大家猜猜看是哪家：））。

在美国的中国菜，只有硅谷一带还比较正宗，或许是因为华人工程师比例不低。但相比国内，还是差了一大截，尤其是在同等价位的情况下。吃不到地道的，丰富多样的中国菜，是每一名海外华人的痛。但此时，我们都无暇顾及这种小事儿（其实是天大的事儿！）。因为我们正在聊的，是价值几个亿的事情。

<br/>

“我们的项目组最近正在尝试使用一些高级的模型，来分析预测用户行为”，大佬说话了。

“嗯”，我点头。其实，搞机器学习的都明白，在很多实际应用上，并不会使用太复杂的算法。很多时候，逻辑回归就能得到很好的结果。更重要的，其实是数据量，数据质量，特征工程，以及超参数的调整。这是因为即使是简单的模型，也会得到不错的结果；而复杂的模型，得到的结果或许更好，但到底好了多少？很可能好出来的程度，和使用它的成本比起来，是不值一提的。

但是，尽管如此，当算法满足基本要求以后，大家也都会朝更高级的算法进军。有意思的是，在这家企业（很多企业其实也都是），大多数朝更高级算法进军的主力人员，是实习生。因为他们本身没有过大的业绩压力，承担得起风险，是做这种探索性工作的绝佳人选。更不用提他们刚从学界出来，离最新的理论更近，也充满了干劲，正着急把学到的理论用在实处呢。而企业此时，更多地是提供给他们平台，数据，算力，和做完整项目的流程经验，等等等等。

毕竟，未来终归是属于他们的。（怪不得前浪总是被拍死在沙滩上，因为毫无探险精神啊！）

<br/>

“我的实习生现在遇到了一个问题。”大佬继续说道，“我们在尝试使用LSTM做分析，可是效果不太理想。我们做出来的结果，和Baseline Model比较，准确率提升地也不够。”

“嗯”，我继续点头。

Baseline Model是机器学习领域的一个术语，简单来说，就是使用最普遍的情况来做结果预测。比如一个猜硬币正反面游戏，最朴素的策略就是永远猜正（或者永远猜反），这样你至少有50%的准确率。再比如说，很多学习不好的同学，应该都做过这件事情：考试里选择题一率选C，这也是利用了Baseline Model来“预测”问题的结果。理论上，这样做至少能拿25%的分数。而之所以选择C，是发现，似乎选择C，能拿到比25%还多的分数。毕竟，选择题的答案不是真正的随机分布的。有意思的是，在极个别的情况下，这样做的考分比另一部分同学正儿八经地答题，得分还高。

我之前曾经写了一篇文章[《网购有助脱单？我还实现了一个准确率99.9%的癌症预测算法呢！》](../2017-09-02/)，其中我所实现的准确率99.9%的癌症预测算法，本质也是一个Baseline Model。简单讲，就是我发现一个疾病的发病率只有0.1%，那么在这种情况下，我们的算法只需要永远预测健康，那么其准确率就是99.9%。Baseline Model的意义，是让我们了解这个问题的基线在哪里，从而让我们不再迷信一个绝对的数值。你告诉我你的预测准确度是99.9%，严格意义来讲是没有意义的。因为如果你的Baseline Model的准确率也是99.9%，你的算法等于没有做任何事情；而如果你的Baseline Model的准确度是99.99%，你的算法反而让结果变差了。但是如果你的Baseline Model的准确率是50%，你的算法结果准确率哪怕仅仅是60%，也是挺不错的一个改善。试想，如果你能以60%的准确度预测抛硬币游戏的正反的话，你应该不会来看这篇文章，而是去笑傲赌场了：） 

<br/>

大佬继续发言了：“我作为supervisor，还是希望我的实习生做出点儿成绩的。”这位大佬是一个负责任的人，这是大家都知道的。我经常通过和这位大佬的交流，来反思：自己为什么不能如此为他人着想？嗯，看来今天这顿饭，要是我请客了。等等，我觉得不对。饭钱是小事儿，我们正在聊几个亿的大事儿！

“所以，”大佬继续不紧不慢的说，“你看有没有可能，我们能让我们的Baseline Model的准确度更低一些？”

大佬顿了一下，夹了口菜。

“越低越好。”

---

P.S. 其实理解不理解Baseline Model可能不重要。反正很容易理解。更重要的是明白：很多时候，成功的关键不是你做得有多完美，而是你比对手好多少：）
